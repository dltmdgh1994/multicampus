{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('C:/Users/s_csmscox/jupyterSave/fashion-mnist_train.csv')\n",
    "test = pd.read_csv('C:/Users/s_csmscox/jupyterSave/fashion-mnist_test.csv')\n",
    "\n",
    "train_label = train['label']\n",
    "train.drop(['label'], axis=1, inplace=True)\n",
    "\n",
    "test_label = test['label']\n",
    "test.drop(['label'], axis=1, inplace=True)\n",
    "\n",
    "### 정규화\n",
    "scaler_train = MinMaxScaler()\n",
    "scaler_train.fit(train)\n",
    "x_data_train_norm = scaler_train.transform(train)\n",
    "\n",
    "scaler_test = MinMaxScaler()\n",
    "scaler_test.fit(train)\n",
    "x_data_test_norm = scaler_test.transform(test)\n",
    "\n",
    "# one hot encoding\n",
    "t_data_train_onehot = to_categorical(train_label)\n",
    "\n",
    "# reshape\n",
    "x_data_train_norm = x_data_train_norm.reshape(60000,28,28,1)\n",
    "x_data_test_norm = x_data_test_norm.reshape(10000,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 128)         32896     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                62730     \n",
      "=================================================================\n",
      "Total params: 104,202\n",
      "Trainable params: 104,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "2/5 [===========>..................] - ETA: 0s - loss: 2.1610 - accuracy: 0.1091WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0530s vs `on_train_batch_end` time: 0.0851s). Check your callbacks.\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 1.8986 - accuracy: 0.3354 - val_loss: 1.1526 - val_accuracy: 0.5392\n",
      "Epoch 2/1000\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.9672 - accuracy: 0.6141 - val_loss: 0.7263 - val_accuracy: 0.7255\n",
      "Epoch 3/1000\n",
      "5/5 [==============================] - 1s 103ms/step - loss: 0.7172 - accuracy: 0.7287 - val_loss: 0.6344 - val_accuracy: 0.7653\n",
      "Epoch 4/1000\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.6153 - accuracy: 0.7708 - val_loss: 0.5582 - val_accuracy: 0.7972\n",
      "Epoch 5/1000\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.5423 - accuracy: 0.7996 - val_loss: 0.5002 - val_accuracy: 0.8238\n",
      "Epoch 6/1000\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.4887 - accuracy: 0.8230 - val_loss: 0.4579 - val_accuracy: 0.8384\n",
      "Epoch 7/1000\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.4513 - accuracy: 0.8385 - val_loss: 0.4313 - val_accuracy: 0.8507\n",
      "Epoch 8/1000\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.4245 - accuracy: 0.8484 - val_loss: 0.4098 - val_accuracy: 0.8503\n",
      "Epoch 9/1000\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.4025 - accuracy: 0.8531 - val_loss: 0.3899 - val_accuracy: 0.8599\n",
      "Epoch 10/1000\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.3801 - accuracy: 0.8614 - val_loss: 0.3737 - val_accuracy: 0.8663\n",
      "Epoch 11/1000\n",
      "5/5 [==============================] - 1s 107ms/step - loss: 0.3632 - accuracy: 0.8677 - val_loss: 0.3497 - val_accuracy: 0.8781\n",
      "Epoch 12/1000\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.3443 - accuracy: 0.8744 - val_loss: 0.3319 - val_accuracy: 0.8850\n",
      "Epoch 13/1000\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.3315 - accuracy: 0.8803 - val_loss: 0.3256 - val_accuracy: 0.8869\n",
      "Epoch 14/1000\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.3219 - accuracy: 0.8833 - val_loss: 0.3139 - val_accuracy: 0.8904\n",
      "Epoch 15/1000\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.3070 - accuracy: 0.8877 - val_loss: 0.3236 - val_accuracy: 0.8845\n",
      "Epoch 16/1000\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.3045 - accuracy: 0.8888 - val_loss: 0.3077 - val_accuracy: 0.8918\n",
      "Epoch 17/1000\n",
      "5/5 [==============================] - 1s 107ms/step - loss: 0.2998 - accuracy: 0.8907 - val_loss: 0.3082 - val_accuracy: 0.8898\n",
      "Epoch 18/1000\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.2878 - accuracy: 0.8953 - val_loss: 0.3022 - val_accuracy: 0.8936\n",
      "Epoch 19/1000\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.2867 - accuracy: 0.8949 - val_loss: 0.2914 - val_accuracy: 0.8969\n",
      "Epoch 20/1000\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.2801 - accuracy: 0.8975 - val_loss: 0.2832 - val_accuracy: 0.9007\n",
      "Epoch 21/1000\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.2677 - accuracy: 0.9028 - val_loss: 0.2975 - val_accuracy: 0.8938\n",
      "Epoch 22/1000\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.2718 - accuracy: 0.9007 - val_loss: 0.2817 - val_accuracy: 0.8973\n",
      "Epoch 23/1000\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.2621 - accuracy: 0.9049 - val_loss: 0.2742 - val_accuracy: 0.9049\n",
      "Epoch 24/1000\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.2561 - accuracy: 0.9063 - val_loss: 0.2718 - val_accuracy: 0.9029\n",
      "Epoch 25/1000\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.2516 - accuracy: 0.9070 - val_loss: 0.2708 - val_accuracy: 0.9041\n",
      "Epoch 26/1000\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.2532 - accuracy: 0.9063 - val_loss: 0.2658 - val_accuracy: 0.9062\n",
      "Epoch 27/1000\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.2480 - accuracy: 0.9087 - val_loss: 0.2828 - val_accuracy: 0.8976\n",
      "Epoch 28/1000\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.2505 - accuracy: 0.9081 - val_loss: 0.2665 - val_accuracy: 0.9058\n",
      "Epoch 29/1000\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.2415 - accuracy: 0.9104 - val_loss: 0.2651 - val_accuracy: 0.9085\n",
      "Epoch 30/1000\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.2358 - accuracy: 0.9134 - val_loss: 0.2575 - val_accuracy: 0.9101\n",
      "Epoch 31/1000\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.2317 - accuracy: 0.9143 - val_loss: 0.2638 - val_accuracy: 0.9048\n",
      "Epoch 32/1000\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.2288 - accuracy: 0.9155 - val_loss: 0.2598 - val_accuracy: 0.9076\n",
      "Epoch 33/1000\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.2248 - accuracy: 0.9174 - val_loss: 0.2556 - val_accuracy: 0.9114\n",
      "Epoch 34/1000\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.2216 - accuracy: 0.9173 - val_loss: 0.2495 - val_accuracy: 0.9127\n",
      "Epoch 35/1000\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.2172 - accuracy: 0.9210 - val_loss: 0.2517 - val_accuracy: 0.9099\n",
      "Epoch 36/1000\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.2158 - accuracy: 0.9206 - val_loss: 0.2510 - val_accuracy: 0.9123\n",
      "Epoch 37/1000\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.2131 - accuracy: 0.9218 - val_loss: 0.2441 - val_accuracy: 0.9149\n",
      "Epoch 38/1000\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.2101 - accuracy: 0.9222 - val_loss: 0.2736 - val_accuracy: 0.9008\n",
      "Epoch 39/1000\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.2309 - accuracy: 0.9145 - val_loss: 0.2515 - val_accuracy: 0.9106\n",
      "Epoch 40/1000\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.2159 - accuracy: 0.9204 - val_loss: 0.2547 - val_accuracy: 0.9114\n",
      "Epoch 41/1000\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.2104 - accuracy: 0.9214 - val_loss: 0.2525 - val_accuracy: 0.9108\n",
      "Epoch 42/1000\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.2063 - accuracy: 0.9243 - val_loss: 0.2517 - val_accuracy: 0.9121\n",
      "Epoch 43/1000\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.2042 - accuracy: 0.9234 - val_loss: 0.2512 - val_accuracy: 0.9113\n",
      "Epoch 44/1000\n",
      "5/5 [==============================] - 1s 101ms/step - loss: 0.2007 - accuracy: 0.9264 - val_loss: 0.2425 - val_accuracy: 0.9151\n",
      "Epoch 45/1000\n",
      "5/5 [==============================] - 1s 101ms/step - loss: 0.1957 - accuracy: 0.9282 - val_loss: 0.2468 - val_accuracy: 0.9142\n",
      "Epoch 46/1000\n",
      "5/5 [==============================] - 1s 101ms/step - loss: 0.1966 - accuracy: 0.9260 - val_loss: 0.2499 - val_accuracy: 0.9129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/1000\n",
      "5/5 [==============================] - 1s 101ms/step - loss: 0.1922 - accuracy: 0.9291 - val_loss: 0.2460 - val_accuracy: 0.9146\n",
      "Epoch 48/1000\n",
      "5/5 [==============================] - 1s 101ms/step - loss: 0.1934 - accuracy: 0.9282 - val_loss: 0.2413 - val_accuracy: 0.9162\n",
      "Epoch 49/1000\n",
      "5/5 [==============================] - 1s 101ms/step - loss: 0.1933 - accuracy: 0.9287 - val_loss: 0.2526 - val_accuracy: 0.9098\n",
      "Epoch 50/1000\n",
      "5/5 [==============================] - 1s 101ms/step - loss: 0.1896 - accuracy: 0.9309 - val_loss: 0.2381 - val_accuracy: 0.9163\n",
      "Epoch 51/1000\n",
      "5/5 [==============================] - 1s 101ms/step - loss: 0.1848 - accuracy: 0.9316 - val_loss: 0.2505 - val_accuracy: 0.9137\n",
      "Epoch 52/1000\n",
      "5/5 [==============================] - 1s 101ms/step - loss: 0.1920 - accuracy: 0.9284 - val_loss: 0.2456 - val_accuracy: 0.9126\n",
      "Epoch 53/1000\n",
      "5/5 [==============================] - 1s 100ms/step - loss: 0.1868 - accuracy: 0.9316 - val_loss: 0.2409 - val_accuracy: 0.9143\n",
      "Epoch 54/1000\n",
      "5/5 [==============================] - 1s 101ms/step - loss: 0.1793 - accuracy: 0.9345 - val_loss: 0.2425 - val_accuracy: 0.9182\n",
      "Epoch 55/1000\n",
      "5/5 [==============================] - 1s 101ms/step - loss: 0.1770 - accuracy: 0.9336 - val_loss: 0.2489 - val_accuracy: 0.9151\n",
      "Epoch 56/1000\n",
      "5/5 [==============================] - 1s 100ms/step - loss: 0.1777 - accuracy: 0.9345 - val_loss: 0.2381 - val_accuracy: 0.9180\n",
      "Epoch 57/1000\n",
      "5/5 [==============================] - 1s 101ms/step - loss: 0.1712 - accuracy: 0.9373 - val_loss: 0.2506 - val_accuracy: 0.9132\n",
      "Epoch 58/1000\n",
      "5/5 [==============================] - 1s 100ms/step - loss: 0.1780 - accuracy: 0.9336 - val_loss: 0.2376 - val_accuracy: 0.9177\n",
      "Epoch 59/1000\n",
      "5/5 [==============================] - 1s 101ms/step - loss: 0.1703 - accuracy: 0.9371 - val_loss: 0.2480 - val_accuracy: 0.9152\n",
      "Epoch 60/1000\n",
      "5/5 [==============================] - 1s 101ms/step - loss: 0.1782 - accuracy: 0.9330 - val_loss: 0.2349 - val_accuracy: 0.9203\n",
      "Epoch 61/1000\n",
      "5/5 [==============================] - 1s 101ms/step - loss: 0.1691 - accuracy: 0.9379 - val_loss: 0.2318 - val_accuracy: 0.9189\n",
      "Epoch 62/1000\n",
      "5/5 [==============================] - 1s 101ms/step - loss: 0.1605 - accuracy: 0.9408 - val_loss: 0.2385 - val_accuracy: 0.9173\n",
      "Epoch 63/1000\n",
      "5/5 [==============================] - 1s 102ms/step - loss: 0.1653 - accuracy: 0.9388 - val_loss: 0.2399 - val_accuracy: 0.9188\n",
      "Epoch 64/1000\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.1607 - accuracy: 0.9410 - val_loss: 0.2403 - val_accuracy: 0.9197\n",
      "Epoch 65/1000\n",
      "5/5 [==============================] - 1s 101ms/step - loss: 0.1624 - accuracy: 0.9395 - val_loss: 0.2432 - val_accuracy: 0.9168\n",
      "Epoch 66/1000\n",
      "5/5 [==============================] - 1s 101ms/step - loss: 0.1621 - accuracy: 0.9390 - val_loss: 0.2420 - val_accuracy: 0.9180\n",
      "Epoch 67/1000\n",
      "5/5 [==============================] - 1s 101ms/step - loss: 0.1593 - accuracy: 0.9405 - val_loss: 0.2428 - val_accuracy: 0.9175\n",
      "Epoch 68/1000\n",
      "5/5 [==============================] - 1s 101ms/step - loss: 0.1567 - accuracy: 0.9419 - val_loss: 0.2413 - val_accuracy: 0.9175\n",
      "Epoch 69/1000\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.1559 - accuracy: 0.9415 - val_loss: 0.2473 - val_accuracy: 0.9164\n",
      "Epoch 70/1000\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.1588 - accuracy: 0.9410 - val_loss: 0.2369 - val_accuracy: 0.9196\n",
      "Epoch 71/1000\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.1538 - accuracy: 0.9428 - val_loss: 0.2438 - val_accuracy: 0.9168\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), padding='same',\n",
    "                 activation='relu',\n",
    "                 input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (2, 2), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128, (2, 2), activation='relu', padding='same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.summary()\n",
    "model.compile(optimizer=Adam(learning_rate=1e-2), loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_data_train_norm, t_data_train_onehot, epochs=1000, verbose=1,\n",
    "                   validation_split=0.3, batch_size=10000, callbacks=[earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'], color='r')\n",
    "plt.plot(history.history['loss'], color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9199\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(x_data_test_norm)\n",
    "pred = []\n",
    "\n",
    "for i in result:\n",
    "    m = i.max()\n",
    "    for j in range(10):\n",
    "        if i[j] == m:\n",
    "            pred.append(j)\n",
    "            break\n",
    "\n",
    "cnt = 0\n",
    "for predict, answer in zip(pred, test_label):\n",
    "    if predict == answer:\n",
    "        cnt += 1\n",
    "\n",
    "print(\"Accuracy : {}\".format((cnt/len(pred))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
