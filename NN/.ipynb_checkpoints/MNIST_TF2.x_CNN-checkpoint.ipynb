{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('C:/Users/s_csmscox/jupyterSave/digital_train.csv')\n",
    "test = pd.read_csv('C:/Users/s_csmscox/jupyterSave/digital_test.csv')\n",
    "\n",
    "train_label = train['label']\n",
    "train.drop(['label'], axis=1, inplace=True)\n",
    "\n",
    "# 정규화\n",
    "scaler_train = MinMaxScaler()\n",
    "scaler_train.fit(train)\n",
    "x_data_train_norm = scaler_train.transform(train)\n",
    "\n",
    "scaler_test = MinMaxScaler()\n",
    "scaler_test.fit(test)\n",
    "x_data_test_norm = scaler_test.transform(test)\n",
    "\n",
    "# one hot encoding\n",
    "t_data_train_onehot = to_categorical(train_label)\n",
    "\n",
    "# reshape\n",
    "x_data_train_norm = x_data_train_norm.reshape(42000,28,28,1)\n",
    "x_data_test_norm = x_data_test_norm.reshape(28000,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 128)         32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                11530     \n",
      "=================================================================\n",
      "Total params: 53,002\n",
      "Trainable params: 53,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 2.2761 - accuracy: 0.1007WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0631s vs `on_train_batch_end` time: 0.1071s). Check your callbacks.\n",
      "3/3 [==============================] - 1s 247ms/step - loss: 2.1993 - accuracy: 0.2032 - val_loss: 1.5741 - val_accuracy: 0.6151\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 1.6989 - accuracy: 0.5052 - val_loss: 1.2873 - val_accuracy: 0.5959\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 1.2335 - accuracy: 0.6082 - val_loss: 1.0826 - val_accuracy: 0.6814\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.9923 - accuracy: 0.7052 - val_loss: 0.6383 - val_accuracy: 0.8222\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.5427 - accuracy: 0.8414 - val_loss: 0.3946 - val_accuracy: 0.8792\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.4229 - accuracy: 0.8741 - val_loss: 0.2969 - val_accuracy: 0.9118\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.3449 - accuracy: 0.9032 - val_loss: 0.2703 - val_accuracy: 0.9237\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.2692 - accuracy: 0.9255 - val_loss: 0.1913 - val_accuracy: 0.9433\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.2152 - accuracy: 0.9394 - val_loss: 0.1669 - val_accuracy: 0.9495\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.1794 - accuracy: 0.9479 - val_loss: 0.1441 - val_accuracy: 0.9544\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.1623 - accuracy: 0.9507 - val_loss: 0.1287 - val_accuracy: 0.9607\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.1435 - accuracy: 0.9566 - val_loss: 0.1127 - val_accuracy: 0.9655\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.1260 - accuracy: 0.9615 - val_loss: 0.0984 - val_accuracy: 0.9695\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.1108 - accuracy: 0.9659 - val_loss: 0.0929 - val_accuracy: 0.9710\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.1018 - accuracy: 0.9691 - val_loss: 0.0849 - val_accuracy: 0.9737\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0938 - accuracy: 0.9707 - val_loss: 0.0790 - val_accuracy: 0.9743\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0854 - accuracy: 0.9740 - val_loss: 0.0749 - val_accuracy: 0.9768\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0797 - accuracy: 0.9761 - val_loss: 0.0720 - val_accuracy: 0.9771\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0751 - accuracy: 0.9769 - val_loss: 0.0670 - val_accuracy: 0.9787\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0712 - accuracy: 0.9777 - val_loss: 0.0634 - val_accuracy: 0.9794\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0673 - accuracy: 0.9795 - val_loss: 0.0611 - val_accuracy: 0.9810\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0613 - accuracy: 0.9808 - val_loss: 0.0580 - val_accuracy: 0.9807\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0600 - accuracy: 0.9818 - val_loss: 0.0564 - val_accuracy: 0.9820\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0554 - accuracy: 0.9828 - val_loss: 0.0534 - val_accuracy: 0.9825\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0531 - accuracy: 0.9832 - val_loss: 0.0519 - val_accuracy: 0.9832\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0491 - accuracy: 0.9852 - val_loss: 0.0504 - val_accuracy: 0.9839\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0487 - accuracy: 0.9846 - val_loss: 0.0492 - val_accuracy: 0.9837\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0455 - accuracy: 0.9859 - val_loss: 0.0487 - val_accuracy: 0.9840\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0450 - accuracy: 0.9852 - val_loss: 0.0466 - val_accuracy: 0.9849\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0427 - accuracy: 0.9867 - val_loss: 0.0463 - val_accuracy: 0.9845\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0411 - accuracy: 0.9869 - val_loss: 0.0454 - val_accuracy: 0.9852\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0385 - accuracy: 0.9878 - val_loss: 0.0443 - val_accuracy: 0.9856\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0383 - accuracy: 0.9876 - val_loss: 0.0447 - val_accuracy: 0.9852\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0367 - accuracy: 0.9884 - val_loss: 0.0439 - val_accuracy: 0.9856\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0354 - accuracy: 0.9890 - val_loss: 0.0439 - val_accuracy: 0.9859\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0339 - accuracy: 0.9888 - val_loss: 0.0425 - val_accuracy: 0.9856\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0325 - accuracy: 0.9895 - val_loss: 0.0424 - val_accuracy: 0.9860\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0315 - accuracy: 0.9900 - val_loss: 0.0415 - val_accuracy: 0.9867\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0296 - accuracy: 0.9907 - val_loss: 0.0406 - val_accuracy: 0.9872\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0291 - accuracy: 0.9906 - val_loss: 0.0404 - val_accuracy: 0.9867\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0277 - accuracy: 0.9916 - val_loss: 0.0395 - val_accuracy: 0.9877\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0257 - accuracy: 0.9918 - val_loss: 0.0396 - val_accuracy: 0.9867\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 0.0281 - accuracy: 0.9906 - val_loss: 0.0417 - val_accuracy: 0.9867\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0258 - accuracy: 0.9917 - val_loss: 0.0411 - val_accuracy: 0.9864\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0252 - accuracy: 0.9927 - val_loss: 0.0440 - val_accuracy: 0.9860\n",
      "Epoch 46/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0266 - accuracy: 0.9913 - val_loss: 0.0410 - val_accuracy: 0.9869\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0245 - accuracy: 0.9917 - val_loss: 0.0395 - val_accuracy: 0.9877\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0237 - accuracy: 0.9924 - val_loss: 0.0391 - val_accuracy: 0.9875\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0239 - accuracy: 0.9918 - val_loss: 0.0390 - val_accuracy: 0.9883\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0216 - accuracy: 0.9930 - val_loss: 0.0400 - val_accuracy: 0.9871\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0221 - accuracy: 0.9929 - val_loss: 0.0375 - val_accuracy: 0.9883\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0201 - accuracy: 0.9937 - val_loss: 0.0401 - val_accuracy: 0.9873\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0201 - accuracy: 0.9931 - val_loss: 0.0375 - val_accuracy: 0.9888\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0186 - accuracy: 0.9939 - val_loss: 0.0380 - val_accuracy: 0.9887\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0185 - accuracy: 0.9940 - val_loss: 0.0377 - val_accuracy: 0.9889\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0183 - accuracy: 0.9939 - val_loss: 0.0370 - val_accuracy: 0.9887\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0182 - accuracy: 0.9940 - val_loss: 0.0383 - val_accuracy: 0.9883\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0172 - accuracy: 0.9941 - val_loss: 0.0367 - val_accuracy: 0.9894\n",
      "Epoch 59/200\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0161 - accuracy: 0.9950 - val_loss: 0.0373 - val_accuracy: 0.9885\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0167 - accuracy: 0.9949 - val_loss: 0.0366 - val_accuracy: 0.9895\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0152 - accuracy: 0.9954 - val_loss: 0.0368 - val_accuracy: 0.9893\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0163 - accuracy: 0.9946 - val_loss: 0.0365 - val_accuracy: 0.9898\n",
      "Epoch 63/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0142 - accuracy: 0.9954 - val_loss: 0.0376 - val_accuracy: 0.9894\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0156 - accuracy: 0.9952 - val_loss: 0.0370 - val_accuracy: 0.9898\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0142 - accuracy: 0.9954 - val_loss: 0.0372 - val_accuracy: 0.9894\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0145 - accuracy: 0.9954 - val_loss: 0.0371 - val_accuracy: 0.9901\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0144 - accuracy: 0.9952 - val_loss: 0.0371 - val_accuracy: 0.9896\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0148 - accuracy: 0.9951 - val_loss: 0.0365 - val_accuracy: 0.9901\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0138 - accuracy: 0.9955 - val_loss: 0.0385 - val_accuracy: 0.9891\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0135 - accuracy: 0.9951 - val_loss: 0.0365 - val_accuracy: 0.9898\n",
      "Epoch 71/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0127 - accuracy: 0.9960 - val_loss: 0.0368 - val_accuracy: 0.9898\n",
      "Epoch 72/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0127 - accuracy: 0.9957 - val_loss: 0.0376 - val_accuracy: 0.9901\n",
      "Epoch 73/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0124 - accuracy: 0.9960 - val_loss: 0.0375 - val_accuracy: 0.9901\n",
      "Epoch 74/200\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.0375 - val_accuracy: 0.9890\n",
      "Epoch 75/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0111 - accuracy: 0.9962 - val_loss: 0.0369 - val_accuracy: 0.9904\n",
      "Epoch 76/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0105 - accuracy: 0.9967 - val_loss: 0.0379 - val_accuracy: 0.9894\n",
      "Epoch 77/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0116 - accuracy: 0.9962 - val_loss: 0.0395 - val_accuracy: 0.9901\n",
      "Epoch 78/200\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0113 - accuracy: 0.9960 - val_loss: 0.0379 - val_accuracy: 0.9898\n",
      "Epoch 79/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0103 - accuracy: 0.9967 - val_loss: 0.0388 - val_accuracy: 0.9903\n",
      "Epoch 80/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0100 - accuracy: 0.9966 - val_loss: 0.0384 - val_accuracy: 0.9903\n",
      "Epoch 81/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0401 - val_accuracy: 0.9898\n",
      "Epoch 82/200\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0107 - accuracy: 0.9964 - val_loss: 0.0374 - val_accuracy: 0.9902\n",
      "Epoch 83/200\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0394 - val_accuracy: 0.9899\n",
      "Epoch 84/200\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0101 - accuracy: 0.9967 - val_loss: 0.0375 - val_accuracy: 0.9898\n",
      "Epoch 85/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0078 - accuracy: 0.9977 - val_loss: 0.0392 - val_accuracy: 0.9902\n",
      "Epoch 86/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0095 - accuracy: 0.9967 - val_loss: 0.0384 - val_accuracy: 0.9901\n",
      "Epoch 87/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0090 - accuracy: 0.9971 - val_loss: 0.0376 - val_accuracy: 0.9900\n",
      "Epoch 88/200\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 0.0387 - val_accuracy: 0.9902\n",
      "Epoch 89/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0089 - accuracy: 0.9971 - val_loss: 0.0393 - val_accuracy: 0.9898\n",
      "Epoch 90/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0096 - accuracy: 0.9970 - val_loss: 0.0395 - val_accuracy: 0.9900\n",
      "Epoch 91/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0091 - accuracy: 0.9973 - val_loss: 0.0386 - val_accuracy: 0.9899\n",
      "Epoch 92/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0080 - accuracy: 0.9973 - val_loss: 0.0380 - val_accuracy: 0.9902\n",
      "Epoch 93/200\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0074 - accuracy: 0.9981 - val_loss: 0.0391 - val_accuracy: 0.9892\n",
      "Epoch 94/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0078 - accuracy: 0.9972 - val_loss: 0.0383 - val_accuracy: 0.9900\n",
      "Epoch 95/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.0385 - val_accuracy: 0.9906\n",
      "Epoch 96/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0083 - accuracy: 0.9977 - val_loss: 0.0393 - val_accuracy: 0.9903\n",
      "Epoch 97/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0076 - accuracy: 0.9975 - val_loss: 0.0412 - val_accuracy: 0.9897\n",
      "Epoch 98/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 0.0403 - val_accuracy: 0.9897\n",
      "Epoch 99/200\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0076 - accuracy: 0.9978 - val_loss: 0.0396 - val_accuracy: 0.9906\n",
      "Epoch 100/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.0396 - val_accuracy: 0.9902\n",
      "Epoch 101/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0068 - accuracy: 0.9978 - val_loss: 0.0392 - val_accuracy: 0.9903\n",
      "Epoch 102/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.0403 - val_accuracy: 0.9897\n",
      "Epoch 103/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.0394 - val_accuracy: 0.9902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0067 - accuracy: 0.9977 - val_loss: 0.0416 - val_accuracy: 0.9891\n",
      "Epoch 105/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0067 - accuracy: 0.9978 - val_loss: 0.0395 - val_accuracy: 0.9902\n",
      "Epoch 106/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0079 - accuracy: 0.9973 - val_loss: 0.0417 - val_accuracy: 0.9897\n",
      "Epoch 107/200\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0073 - accuracy: 0.9974 - val_loss: 0.0401 - val_accuracy: 0.9901\n",
      "Epoch 108/200\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.0397 - val_accuracy: 0.9910\n",
      "Epoch 109/200\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0055 - accuracy: 0.9985 - val_loss: 0.0410 - val_accuracy: 0.9898\n",
      "Epoch 110/200\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.0409 - val_accuracy: 0.9902\n",
      "Epoch 111/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0062 - accuracy: 0.9978 - val_loss: 0.0401 - val_accuracy: 0.9905\n",
      "Epoch 112/200\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0057 - accuracy: 0.9981 - val_loss: 0.0409 - val_accuracy: 0.9907\n",
      "Epoch 113/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.0413 - val_accuracy: 0.9908\n",
      "Epoch 114/200\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.0415 - val_accuracy: 0.9903\n",
      "Epoch 115/200\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.0397 - val_accuracy: 0.9907\n",
      "Epoch 116/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0056 - accuracy: 0.9981 - val_loss: 0.0401 - val_accuracy: 0.9908\n",
      "Epoch 117/200\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.0397 - val_accuracy: 0.9909\n",
      "Epoch 118/200\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.0413 - val_accuracy: 0.9902\n",
      "Epoch 119/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.0411 - val_accuracy: 0.9905\n",
      "Epoch 120/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.0408 - val_accuracy: 0.9907\n",
      "Epoch 121/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.0403 - val_accuracy: 0.9912\n",
      "Epoch 122/200\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.0415 - val_accuracy: 0.9902\n",
      "Epoch 123/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.0421 - val_accuracy: 0.9910\n",
      "Epoch 124/200\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.0425 - val_accuracy: 0.9904\n",
      "Epoch 125/200\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.0433 - val_accuracy: 0.9910\n",
      "Epoch 126/200\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.0436 - val_accuracy: 0.9902\n",
      "Epoch 127/200\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.0443 - val_accuracy: 0.9909\n",
      "Epoch 128/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.0422 - val_accuracy: 0.9906\n",
      "Epoch 129/200\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.0435 - val_accuracy: 0.9905\n",
      "Epoch 130/200\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0043 - accuracy: 0.9985 - val_loss: 0.0422 - val_accuracy: 0.9902\n",
      "Epoch 131/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.0416 - val_accuracy: 0.9909\n",
      "Epoch 132/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.0424 - val_accuracy: 0.9910\n",
      "Epoch 133/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0042 - accuracy: 0.9985 - val_loss: 0.0412 - val_accuracy: 0.9910\n",
      "Epoch 134/200\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.0418 - val_accuracy: 0.9911\n",
      "Epoch 135/200\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.0423 - val_accuracy: 0.9909\n",
      "Epoch 136/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.0445 - val_accuracy: 0.9911\n",
      "Epoch 137/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0438 - val_accuracy: 0.9902\n",
      "Epoch 138/200\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.0453 - val_accuracy: 0.9909\n",
      "Epoch 139/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.0440 - val_accuracy: 0.9904\n",
      "Epoch 140/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.0428 - val_accuracy: 0.9910\n",
      "Epoch 141/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 0.0459 - val_accuracy: 0.9906\n",
      "Epoch 142/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.0493 - val_accuracy: 0.9901\n",
      "Epoch 143/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0041 - accuracy: 0.9984 - val_loss: 0.0446 - val_accuracy: 0.9911\n",
      "Epoch 144/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.0450 - val_accuracy: 0.9905\n",
      "Epoch 145/200\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.0470 - val_accuracy: 0.9896\n",
      "Epoch 146/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.0447 - val_accuracy: 0.9910\n",
      "Epoch 147/200\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.0446 - val_accuracy: 0.9904\n",
      "Epoch 148/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.0435 - val_accuracy: 0.9906\n",
      "Epoch 149/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0447 - val_accuracy: 0.9910\n",
      "Epoch 150/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.0454 - val_accuracy: 0.9902\n",
      "Epoch 151/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 0.0444 - val_accuracy: 0.9913\n",
      "Epoch 152/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0430 - val_accuracy: 0.9908\n",
      "Epoch 153/200\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.0466 - val_accuracy: 0.9908\n",
      "Epoch 154/200\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0033 - accuracy: 0.9986 - val_loss: 0.0466 - val_accuracy: 0.9906\n",
      "Epoch 155/200\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.0462 - val_accuracy: 0.9908\n",
      "Epoch 156/200\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.0454 - val_accuracy: 0.9908\n",
      "Epoch 157/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0036 - accuracy: 0.9987 - val_loss: 0.0460 - val_accuracy: 0.9906\n",
      "Epoch 158/200\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0470 - val_accuracy: 0.9900\n",
      "Epoch 159/200\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0454 - val_accuracy: 0.9905\n",
      "Epoch 160/200\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.0469 - val_accuracy: 0.9902\n",
      "Epoch 161/200\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0463 - val_accuracy: 0.9906\n",
      "Epoch 162/200\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.0440 - val_accuracy: 0.9915\n",
      "Epoch 163/200\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0485 - val_accuracy: 0.9900\n",
      "Epoch 164/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0471 - val_accuracy: 0.9906\n",
      "Epoch 165/200\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0485 - val_accuracy: 0.9907\n",
      "Epoch 166/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0502 - val_accuracy: 0.9905\n",
      "Epoch 167/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.0492 - val_accuracy: 0.9908\n",
      "Epoch 168/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.0478 - val_accuracy: 0.9906\n",
      "Epoch 169/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.0466 - val_accuracy: 0.9905\n",
      "Epoch 170/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0440 - val_accuracy: 0.9917\n",
      "Epoch 171/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0472 - val_accuracy: 0.9902\n",
      "Epoch 172/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0451 - val_accuracy: 0.9908\n",
      "Epoch 173/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0025 - accuracy: 0.9989 - val_loss: 0.0451 - val_accuracy: 0.9917\n",
      "Epoch 174/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.0466 - val_accuracy: 0.9904\n",
      "Epoch 175/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0451 - val_accuracy: 0.9913\n",
      "Epoch 176/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.0457 - val_accuracy: 0.9906\n",
      "Epoch 177/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.0449 - val_accuracy: 0.9910\n",
      "Epoch 178/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.0463 - val_accuracy: 0.9911\n",
      "Epoch 179/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0496 - val_accuracy: 0.9899\n",
      "Epoch 180/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0466 - val_accuracy: 0.9908\n",
      "Epoch 181/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.0517 - val_accuracy: 0.9902\n",
      "Epoch 182/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.0510 - val_accuracy: 0.9898\n",
      "Epoch 183/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 0.0465 - val_accuracy: 0.9916\n",
      "Epoch 184/200\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0480 - val_accuracy: 0.9909\n",
      "Epoch 185/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.0494 - val_accuracy: 0.9903\n",
      "Epoch 186/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.0496 - val_accuracy: 0.9907\n",
      "Epoch 187/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.0485 - val_accuracy: 0.9912\n",
      "Epoch 188/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.0459 - val_accuracy: 0.9913\n",
      "Epoch 189/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.0486 - val_accuracy: 0.9910\n",
      "Epoch 190/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.0489 - val_accuracy: 0.9909\n",
      "Epoch 191/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0465 - val_accuracy: 0.9910\n",
      "Epoch 192/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0466 - val_accuracy: 0.9907\n",
      "Epoch 193/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.0467 - val_accuracy: 0.9910\n",
      "Epoch 194/200\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0019 - accuracy: 0.9993 - val_loss: 0.0504 - val_accuracy: 0.9906\n",
      "Epoch 195/200\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.0501 - val_accuracy: 0.9908\n",
      "Epoch 196/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0489 - val_accuracy: 0.9911\n",
      "Epoch 197/200\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0478 - val_accuracy: 0.9908\n",
      "Epoch 198/200\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.0478 - val_accuracy: 0.9911\n",
      "Epoch 199/200\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.0494 - val_accuracy: 0.9908\n",
      "Epoch 200/200\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.0487 - val_accuracy: 0.9910\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), strides=(1, 1), padding='same',\n",
    "                 activation='relu',\n",
    "                 input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Conv2D(64, (2, 2), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128, (2, 2), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.summary()\n",
    "model.compile(optimizer=Adam(learning_rate=1e-2), loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_data_train_norm, t_data_train_onehot, epochs=200, verbose=1,\n",
    "                   validation_split=0.3, batch_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAZaElEQVR4nO3dfYwcd33H8ff3Hn1nn89x7kyME8cJdlolAYqxEsxDFalAk4jWoa1CUHloWjUEgVoKaUkITVupqlpakKAULLcNKShNqhYopnVoKx5KoBiwUzux89A4qRubnJ/jO5/vfOfzffvHb8Y3t7dP59vd2Zn9vKTR7M7M7nxvdu8zv/3t7Iy5OyIikn1taRcgIiK1oUAXEckJBbqISE4o0EVEckKBLiKSEx1prXhgYMDXrFmT1upFRDJp586dx9x9sNi81AJ9zZo17NixI63Vi4hkkpn9X6l56nIREckJBbqISE4o0EVEckKBLiKSEwp0EZGcUKCLiOSEAl1EJCcyF+h79sDv/z4cPZp2JSIizSVzgf700/DHfwyHDqVdiYhIc8lcoPf0hPH4eLp1iIg0GwW6iEhOKNBFRHJCgS4ikhMKdBGRnFCgi4jkhAJdRCQnFOgiIjmhQBcRyYnMBXp7O3R2KtBFRAplLtAhtNIV6CIis2U20MfG0q5CRKS5ZDbQ1UIXEZlNgS4ikhMVA93MLjOzb5vZU2a218x+u8gyZmafMbN9Zva4ma2vT7mBAl1EZK6OKpaZAj7i7o+ZWR+w08z+w92fTCxzE7AuGq4HPh+N60KBLiIyV8UWursPuftj0e1TwFPAqoLFNgFf9GA7sMzMVta82ogCXURkrnn1oZvZGuA1wA8LZq0CDiTuH2Ru6GNmd5jZDjPbcXQB15BToIuIzFV1oJvZEuDLwIfcfaRwdpGH+JwJ7lvcfYO7bxgcHJxfpQkKdBGRuaoKdDPrJIT5g+7+lSKLHAQuS9y/FHhx4eUVp0AXEZmrmqNcDPhb4Cl3/1SJxbYC74mOdnkdMOzuQzWscxYFuojIXNUc5fIG4N3AE2a2K5r2MWA1gLtvBrYBNwP7gDHg9ppXmqBAFxGZq2Kgu/v3KN5HnlzGgQ/UqqhK4kB3BytbmYhI68jsL0Wnp+Hs2bQrERFpHpkNdFC3i4hIkgJdRCQnFOgiIjmhQBcRyQkFuohITijQRURyQoEuIpITCnQRkZxQoIuI5IQCXUQkJxToIiI5oUAXEckJBbqISE5kMtC7usJpcxXoIiIzMhnoZrrIhYhIoUwGOijQRUQKKdBFRHJCgS4ikhMKdBGRnMhsoPf2KtBFRJIyG+hqoYuIzKZAFxHJCQW6iEhOKNBFRHJCgS4ikhMKdBGRnFCgi4jkRKYDfXISzp1LuxIRkeaQ6UAHOHMm3TpERJpF5gNd3S4iIoECXUQkJxToIiI5oUAXEckJBbqISE4o0EVEcqJioJvZ/WZ2xMz2lJh/g5kNm9muaLiv9mXOpUAXEZmto4plHgA+C3yxzDKPuvvbalJRlRToIiKzVWyhu/t3gRMNqGVeFOgiIrPVqg99o5ntNrNHzOyaUguZ2R1mtsPMdhw9enRBK1Sgi4jMVotAfwy43N1fDfwl8M+lFnT3Le6+wd03DA4OLmilCnQRkdkWHOjuPuLuo9HtbUCnmQ0suLIKFOgiIrMtONDN7BIzs+j2ddFzHl/o81ayaFEYK9BFRIKKR7mY2UPADcCAmR0E/gDoBHD3zcCvAO83sylgHLjN3b1uFUfa2qC7W4EuIhKrGOju/s4K8z9LOKyx4XSRCxGRGZn9pSiEQB8bS7sKEZHmkPlAVwtdRCRQoIuI5IQCXUQkJxToIiI5oUAXEckJBbqISE4o0EVEckKBLiKSEwp0EZGcUKCLiORELgK9/qcCExFpfpkPdICJiXTrEBFpBrkIdHW7iIgo0EVEckOBLiKSEwp0EZGcUKCLiOREpgO9ry+MT51Ktw4RkWaQ6UBfvjyMX3op3TpERJpBLgL9xIl06xARaQYKdBGRnMh0oPf0QHe3Al1EBDIe6Gahla5AFxHJeKCDAl1EJKZAFxHJCQW6iEhOKNBFRHJCgS4ikhOZD/SLL4axMThzJu1KRETSlflA14+LREQCBbqISE4o0EVEckKBLiKSEwp0EZGcUKCLiORExUA3s/vN7IiZ7Skx38zsM2a2z8weN7P1tS+ztCVLoKNDgS4iUk0L/QHgxjLzbwLWRcMdwOcXXlb1dMZFEZGgo9IC7v5dM1tTZpFNwBfd3YHtZrbMzFa6+1CtiqxEgV6F6WmYmoKzZ2ePz50D97CMexjOnoXJyZnBHRYvDstMTZV+XDwAdHaGcXI909MzyxS7HS+THJLzzcJzDg9De3v4eBb/bcnlk8P0dLiK+LlzYfm2trnP2d0NExMzVxs3mxmSf1+srS0MZmH7nDkzs52S4sdf6P3p6dnbxD383fG6Y8n1LuR2tYo9ptTz1GPZPKzrLW+BW24pvvwCVAz0KqwCDiTuH4ymzQl0M7uD0Ipn9erVNVh1kFqgT07CyZMhDE6ehIMHZwLjxInwz2cGhw/D6dMzATkxUfx2uXnx7fZ26O8P4TM8DCMjIWyXLg3//GfPzg3ts2dDIEg2xTsQmAn3cpJhP9/bhZI70lLrqPQ89Vg26+u65JKmDfRif0HRXZW7bwG2AGzYsOECmgbF9fWFPK2JkRHYtQteeAGOHIGjR8Nw/HgYTpwIV6U+eTKcc2C+2tpCi7CrKwzx7WLTliyZPb2rK4T28DAsWgTLloU/fnQUTp0KreKOjjBO3i43LW7txW84s9nr6+oK00+fDvM6OsJOJd5ZJR+XvH/27Mzy8XridSXXmZzW1ja7BZp8jNlMS7m/P4Ta6Gjx5QqHxYvD/NHR8LjC55yYCH9nb2+oPdnCL/z7ki3/6enwuEWLwrgt0YNZ2Cq7kPuF27hwfrkglpZUi0A/CFyWuH8p8GINnrdqPT3w4oWscf9+ePRR+MEPYPv2cP+ll2Yv09EBAwNhuPhiuOoquOiiMCxbFoaentBCXrVq5nHLl8/8069YEYK3qyv8k0o6li5t3LoqdafU+vlFqE2gbwU+aGYPA9cDw43sP4fQsIq7P8s6cwaefBL+5V/gK1+B3bvD9L4+uP56eMMbQii/6lWwdm0I4v5+/fOISCZUDHQzewi4ARgws4PAHwCdAO6+GdgG3AzsA8aA2+tVbCm9vRV6P3buhD/6I9i2LXRZmMHrXw9/8Rfw1rfC1Ver5SwimVfNUS7vrDDfgQ/UrKIL0NNTItDd4ROfgHvuCV0jH/4wrF8PN9wQvpQQEcmRWnS5pK5kl8vv/A58+tPwjnfAli2N7UMVEWmwzP/0H0KgT0yE3pTzHn44hPlv/RY89JDCXERyLxeB3tMTxudb6fv3w2/+JrzxjaGfXF9qikgLyEWgx4cPnw/0u+4Khws++ODMLxZFRHIuV4E+NgZ861vw5S/Dxz4GNfw1qohIs8tFoMddLmOj0/CRj8CaNWEsItJCcnOUC8DY178Zfrb/pS+Fn2OLiLSQXLTQz/ehf+4LcM018M6yh86LiORSLlro57tcDhyDv79Xv/oUkZaUqxb6GL3w2temW4yISEpyFejj9OjIFhFpWbkI9PNdLv0v15ehItKychHo57tcLlpVfkERkRzLVaCP9+sMiiLSunIR6Is6w1m5xvpelnIlIiLpyUWgtx0eYhHjjPVcnHYpIiKpycVx6OzfTy89jC1annYlIiKpyUULnf376WGc8S6d81xEWlduAr2XMcbalqRdiYhIavIT6B2TjE3kowdJRORC5CPQn3+enkVe/LqiIiItIh+B/uST9Pa1hwtciIi0qOwH+rFjcPgwvcu6Fegi0tKyH+h79wLQO9irLhcRaWm5CfSeFUvVQheRlpb9QN+zB/r76R3oVaCLSEvLfqDv3QvXXEPvYlOXi4i0tGwHuntooV97LT09MDYWJomItKJsB/qhQ3DiRGih94Ywn5hIuygRkXRkO9CjL0S59tqZi1yoH11EWlS2A33PnjC+5przl6FTP7qItKpsB/revTAwACtWqIUuIi0v24EefSGKmQJdRFpedgPd/fwhi4C6XESk5WU30A8cgFOnQgsd1EIXkZaX3UBPfCEKsGxZuHv8eDrliIikrapAN7MbzewZM9tnZncXmX+DmQ2b2a5ouK/2pRaID1mMAv3KK8PdffvqvmYRkaZU8RI/ZtYO/BXwFuAg8GMz2+ruTxYs+qi7v60ONRa3Zw+sXAnLw4Wh+/rgkksU6CLSuqppoV8H7HP35919EngY2FTfsqrw9NNw9dWzJq1dq0AXkdZVTaCvAg4k7h+MphXaaGa7zewRM7um2BOZ2R1mtsPMdhw9evQCyk04cQJWrJg1ae1aePbZhT2tiEhWVRPoVmRa4SmwHgMud/dXA38J/HOxJ3L3Le6+wd03DA4OzqvQOUZGYOnSWZPWrYOhITh9emFPLSKSRdUE+kHgssT9S4EXkwu4+4i7j0a3twGdZjZQsyqLGR6G/v5Zk9auDePnnqvrmkVEmlI1gf5jYJ2ZXWFmXcBtwNbkAmZ2iZlZdPu66HnrdwDhxEQYClrocaCr20VEWlHFo1zcfcrMPgj8G9AO3O/ue83szmj+ZuBXgPeb2RQwDtzmXsczk4+MhHGJFrq+GBWRVlQx0OF8N8q2gmmbE7c/C3y2tqWVEQd6QQt96dLwPakCXURaUTZ/KVoi0CF8MaouFxFpRdkM9OHhMC7ocoHww9Fdu2B6urEliYikLZuBXqaF/rrXhbx/5pkG1yQikrJsBnqZFvrGjWH8gx80sB4RkSaQzUAv00K/6iq46CIFuoi0nmwGepkWelsbXH89bN/e4JpERFKWzUAfGYGuLujuLjp748Zwdt0490VEWkF2A71Id0ts48Zwhbof/aiBNYmIpCybgV7kPC5J110HZup2EZHWks1Ar9BC7+8Pp0rXF6Mi0kqyGegVWugQjkffvl0/MBKR1pHNQK/QQofQj/7SSzoNgIi0juwGeoUWun5gJCKtJpuBPjxcsYX+0z8dMl+BLiKtInuB7l5Vl0v8A6P/+q8G1SUikrLsBfr4OExNVexyAXjzm2HPHti/v/5liYikLXuBXuY8LoVuuSWMv/a1+pUjItIsshvoVbTQ160L50f/6lfrXJOISBPIXqDHJ2ipooUO8Pa3w6OPwrFjdaxJRKQJZC/Q59HlAqHbZXoa/umf6leSiEgzyF6glzl1bjHr18NrXwuf/CScO1fHukREUpa9QF+7Fj76UXj5y6ta3AzuuQf27VMrXUTyzdw9lRVv2LDBd+zY0ZB1TU+HL0fb2uCHP4QlSxqyWhGRmjOzne6+odi87LXQL0BbG3zqU+HC0Zs2wZkzaVckIlJ7LRHoADfdBA88AN/+Ntx6K5w9m3ZFIiK11TKBDvCud8HnPgdf/zq8+936klRE8qUj7QIa7c47YXQUfvd3wyVJv/CF0CUjIpJ1LRfoAHfdFU4Jc9994QvT+++Hzs60qxIRWZiWDHSAj388tMw//nEYGoLPfCZctk5EJKtatrPBDO69N7TOt2+Ha6+F226DvXvTrkxE5MK0bKDHbr89nF737rvhX/8VXvnKcBTM976nL01FJFtaPtABBgbgT/4kBPs998Ajj8Cb3gSXXBIC/6GH4IUX0q5SRKS8lvil6HwND8M3vgFbt8K2bXDyZJh+6aXhohm33hrOQHDppdDTk2qpItJiyv1SVIFewdQUPPEEfP/7YXjkkZnzg3V1wetfD696VfhCdeNGGByEZcsU9CJSHwr0GjpzJvSvDw3B7t3wne+EUwqMjs4sYxYurjEwAH19cPnlcMUVsGZNGC9dGo6BHxwM55UxS+uvEZGsKRfoLXvY4oVatCh0u0D4tSmE61Y//3w48dfICBw6FFr1w8Phwho7dsDx46Wfb8WK4kPc2l+6NJwteOXKcLz8Cy/AxRfDqlXQ3h52MpOTVZ8iXkRyqqpAN7MbgU8D7cDfuPufFsy3aP7NwBjwa+7+WI1rbVpm8IpXhKGUU6fCl67798Pp0yGEjx2Dw4fhyJEwHDoEjz8ebk9OVrfujo7QLQQh0C+6CBYvht7eMFRzu7c3dBHFQ39/6E6amJjpPjp1CpYvD/dPngyfMBYvDn/79HQ4IujcubDDaW9f0OYUkQtUMdDNrB34K+AtwEHgx2a21d2fTCx2E7AuGq4HPh+NJdLXFw6JfOUrKy/rHlr6R46E8chICNGf/CScVGz16tDiHxoKO4a+vhCkBw6ETwVjY2GnMTYWdhrx7eT0WvS0tbWFMC8Uh3280+jqCjuezs4wdHXN7ETcQ83uYUeQHDo65k7r6QldVwBHj4YdSnJ+XNP0dFjXkiVh6O4OO77k0NUVlj92LDx28eKwbFxvsobCWpL329pCHYVDqenFhpEReOml8Ilt8eLwd8anpGhvD3W5h1rPnVvYuqpdthbLuYfXwj0M8euVRjdjXEOxU33EdcZ/S1ZV00K/Dtjn7s8DmNnDwCYgGeibgC966JDfbmbLzGyluw/VvOIWYBZayVVelGne3EPrOw73+BPDmTPh/vBwmN/VFW6Pj4edxvHjIXSWLw/zh4fnBu7kZHi+eBgbCzuhqamZ8ZkzMzses9DqN5tp5cfD1NTcaaOjcOJE+Dt6esLjksvF2y/+5CDNqa1t9s4yuSOOdwBQeRzvIOLniKfF4vfVxMTMp9729rCDb2+f/b6Ml1+0KLy3Osqko9lMA6Wzc2bnlaytXN3vex/83u9Vv72qVU2grwIOJO4fZG7ru9gyq4BZgW5mdwB3AKxevXq+tUqNxG/aRYtCX3zWxDuSYhcqiVuBEP6RT58OO4GJifCP19ExEySTk2GZeBuMjoZhcnJmJ5HcWRTuYOL7yRZo4VBuXnLo6wvdZfGOdnx8ZocU78ggfNHe0bHw9TVqucLWu/vsbZfcpsU+7UD5cdzdNzU1s87kewHCc3Z3h/e7WXh949c4fk/EXYVTU2Hbj4+X/2Hh9HRYdnJy9qm4C2ssVffll5d+7oWoJtCLfQAp/MBezTK4+xZgC4SjXKpYt8gc5T65JP+R2tvD9wrVflnc3Z3NHZxIrJpfih4ELkvcvxR48QKWERGROqom0H8MrDOzK8ysC7gN2FqwzFbgPRa8DhhW/7mISGNV7HJx9ykz+yDwb4TDFu93971mdmc0fzOwjXDI4j7CYYu3169kEREppqrj0N19GyG0k9M2J2478IHaliYiIvOhsy2KiOSEAl1EJCcU6CIiOaFAFxHJidROn2tmR4H/u8CHDwDHalhOLTVrbaprfpq1Lmje2lTX/FxoXZe7+2CxGakF+kKY2Y5S5wNOW7PWprrmp1nrguatTXXNTz3qUpeLiEhOKNBFRHIiq4G+Je0CymjW2lTX/DRrXdC8tamu+al5XZnsQxcRkbmy2kIXEZECCnQRkZzIXKCb2Y1m9oyZ7TOzu1Os4zIz+7aZPWVme83st6Ppf2hmPzGzXdFwcwq17TezJ6L174imLTez/zCzZ6PxRSnU9VOJ7bLLzEbM7ENpbDMzu9/MjpjZnsS0ktvIzO6J3nPPmNnPN7iuPzezp83scTP7qpkti6avMbPxxHbbXPKJ61NXydetUdurTG3/kKhrv5ntiqY3ZJuVyYf6vsfcPTMD4fS9zwFXAl3AbuDqlGpZCayPbvcB/wNcDfwhcFfK22k/MFAw7RPA3dHtu4E/a4LX8hBweRrbDPhZYD2wp9I2il7X3UA3cEX0HmxvYF1vBTqi23+WqGtNcrkUtlfR162R26tUbQXzPwnc18htViYf6voey1oL/fwFq919EogvWN1w7j7k7o9Ft08BTxGuo9qsNgF/F93+O+CW9EoB4OeA59z9Qn8tvCDu/l3gRMHkUttoE/Cwu0+4+/8Szvt/XaPqcvd/d/foMsZsJ1wRrKFKbK9SGra9KtVmZgbcCjxUr/WXqKlUPtT1PZa1QC91MepUmdka4DXAD6NJH4w+Ht+fRtcG4Xqu/25mO6MLcwO8zKOrSEXjFSnUlXQbs//J0t5mUHobNdP77teBRxL3rzCz/zaz/zSzN6VQT7HXrZm215uAw+7+bGJaQ7dZQT7U9T2WtUCv6mLUjWRmS4AvAx9y9xHg88ArgJ8Bhggf9xrtDe6+HrgJ+ICZ/WwKNZRk4VKGvwj8YzSpGbZZOU3xvjOze4Ep4MFo0hCw2t1fA3wY+Hszq/KS2DVR6nVriu0VeSezGw4N3WZF8qHkokWmzXubZS3Qm+pi1GbWSXixHnT3rwC4+2F3P+fu08BfU8ePmqW4+4vR+Ajw1aiGw2a2Mqp7JXCk0XUl3AQ85u6HoTm2WaTUNkr9fWdm7wXeBvyqR52u0cfz49HtnYR+16saVVOZ1y317QVgZh3ALwH/EE9r5DYrlg/U+T2WtUCv5oLVDRH1zf0t8JS7fyoxfWVisbcDewofW+e6FptZX3yb8IXaHsJ2em+02HuBrzWyrgKzWk1pb7OEUttoK3CbmXWb2RXAOuBHjSrKzG4EPgr8oruPJaYPmll7dPvKqK7nG1hXqdct1e2V8GbgaXc/GE9o1DYrlQ/U+z1W72976/Dt8c2Eb4yfA+5NsY43Ej4SPQ7sioabgS8BT0TTtwIrG1zXlYRvy3cDe+NtBFwMfBN4NhovT2m79QLHgf7EtIZvM8IOZQg4S2gd/Ua5bQTcG73nngFuanBd+wj9q/H7bHO07C9Hr/Fu4DHgFxpcV8nXrVHbq1Rt0fQHgDsLlm3INiuTD3V9j+mn/yIiOZG1LhcRESlBgS4ikhMKdBGRnFCgi4jkhAJdRCQnFOgiIjmhQBcRyYn/B7n3uwHCO6i7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'], color='r')\n",
    "plt.plot(history.history['loss'], color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 값 : 8\n"
     ]
    }
   ],
   "source": [
    "# 공식을 이용해서 직접 img를 흑백처리\n",
    "\n",
    "img = np.asarray(Image.open('C:/Users/s_csmscox/jupyterSave/8.png'))\n",
    "\n",
    "# 그레이 스케일링\n",
    "r = 0.2989\n",
    "g = 0.5870\n",
    "b = 0.1140\n",
    "gray = img[:, :, 0] * r + img[:, :, 1] * g + img[:, :, 2] * b\n",
    "img = Image.fromarray(gray)\n",
    "\n",
    "# 사이즈 조절\n",
    "img = img.resize((28,28))\n",
    "\n",
    "# 예측\n",
    "img = np.asarray(img)\n",
    "plt.imshow(img, cmap='gray') # cmap='gray_r의 경우 흑백 반전 = Greys'\n",
    "plt.show()\n",
    "\n",
    "img = 255 - img\n",
    "norm_img = scaler_test.transform(img.reshape(1,-1))\n",
    "norm_img = norm_img.reshape(1,28,28,1)\n",
    "result = model.predict(norm_img)\n",
    "\n",
    "for i in result:\n",
    "    m = i.max()\n",
    "    for j in range(10):\n",
    "        if i[j] == m:\n",
    "            print(\"예측 값 : {}\".format(j))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(x_data_test_norm)\n",
    "ans = []\n",
    "\n",
    "for i in result:\n",
    "    m = i.max()\n",
    "    for j in range(10):\n",
    "        if i[j] == m:\n",
    "            ans.append(j)\n",
    "            break\n",
    "\n",
    "sub = pd.read_csv('C:/Users/s_csmscox/jupyterSave/sample_submission.csv')\n",
    "sub['Label'] = ans\n",
    "sub.to_csv('C:/Users/s_csmscox/jupyterSave/sample_submission10.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
