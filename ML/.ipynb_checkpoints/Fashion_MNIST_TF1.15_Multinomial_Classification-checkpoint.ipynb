{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('C:/Users/s_csmscox/jupyterSave/fashion-mnist_train.csv')\n",
    "test = pd.read_csv('C:/Users/s_csmscox/jupyterSave/fashion-mnist_test.csv')\n",
    "\n",
    "train_label = train['label']\n",
    "train.drop(['label'], axis=1, inplace=True)\n",
    "\n",
    "test_label = test['label']\n",
    "test.drop(['label'], axis=1, inplace=True)\n",
    "\n",
    "### 정규화\n",
    "scaler_train = MinMaxScaler()\n",
    "scaler_train.fit(train)\n",
    "norm_train_x = scaler_train.transform(train)\n",
    "\n",
    "scaler_test = MinMaxScaler()\n",
    "scaler_test.fit(train)\n",
    "norm_test_x = scaler_test.transform(test)\n",
    "\n",
    "### tensorflow 기능을 이용해서 one hot encoding을 생성\n",
    "sess = tf.Session()\n",
    "onehot_train_label = sess.run(tf.one_hot(train_label, depth=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,784], dtype=tf.float32)\n",
    "T = tf.placeholder(shape=[None,10], dtype=tf.float32)\n",
    "\n",
    "# Weight & bias\n",
    "W = tf.Variable(tf.random.normal([784,10]), name='weight')\n",
    "b = tf.Variable(tf.random.normal([10]), name='bias')\n",
    "\n",
    "# Hypothesis\n",
    "logit = tf.matmul(X,W) + b\n",
    "H = tf.nn.softmax(logit)  # softmax activation function\n",
    "\n",
    "# loss function\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit,\n",
    "                                                                 labels=T))\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(loss)\n",
    "\n",
    "# parameter\n",
    "num_of_epoch = 1000\n",
    "batch_size = 10000\n",
    "\n",
    "# 학습용 함수\n",
    "def run_train(sess,train_x, train_t):\n",
    "    print('### 학습 시작 ###')\n",
    "    # 초기화\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(num_of_epoch):\n",
    "        total_batch = int(train_x.shape[0] / batch_size)\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_x = train_x[i*batch_size:(i+1)*batch_size]\n",
    "            batch_t = train_t[i*batch_size:(i+1)*batch_size]           \n",
    "            _, loss_val = sess.run([train,loss],\n",
    "                                   feed_dict={X: batch_x, T: batch_t})\n",
    "            \n",
    "        if step % 100 == 0:\n",
    "            print('Loss : {}'.format(loss_val))\n",
    "    print('### 학습 종료 ###')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 학습 시작 ###\n",
      "Loss : 14.508769989013672\n",
      "Loss : 1.8554534912109375\n",
      "Loss : 1.4533017873764038\n",
      "Loss : 1.2639514207839966\n",
      "Loss : 1.1472113132476807\n",
      "Loss : 1.0649347305297852\n",
      "Loss : 1.002381443977356\n",
      "Loss : 0.9524260759353638\n",
      "Loss : 0.9111851453781128\n",
      "Loss : 0.8763111233711243\n",
      "### 학습 종료 ###\n",
      "측정한 각각의 결과값 : 0.7805833220481873\n",
      "### 학습 시작 ###\n",
      "Loss : 11.673635482788086\n",
      "Loss : 1.72151517868042\n",
      "Loss : 1.3737021684646606\n",
      "Loss : 1.2089762687683105\n",
      "Loss : 1.1043813228607178\n",
      "Loss : 1.0291041135787964\n",
      "Loss : 0.9712395668029785\n",
      "Loss : 0.9249066114425659\n",
      "Loss : 0.8867018818855286\n",
      "Loss : 0.8544744849205017\n",
      "### 학습 종료 ###\n",
      "측정한 각각의 결과값 : 0.777916669845581\n",
      "### 학습 시작 ###\n",
      "Loss : 11.427326202392578\n",
      "Loss : 1.7004327774047852\n",
      "Loss : 1.353205680847168\n",
      "Loss : 1.193374752998352\n",
      "Loss : 1.0928010940551758\n",
      "Loss : 1.0203617811203003\n",
      "Loss : 0.9644642472267151\n",
      "Loss : 0.9195244312286377\n",
      "Loss : 0.8823434710502625\n",
      "Loss : 0.8509107232093811\n",
      "### 학습 종료 ###\n",
      "측정한 각각의 결과값 : 0.7838333249092102\n",
      "### 학습 시작 ###\n",
      "Loss : 16.526134490966797\n",
      "Loss : 1.9513952732086182\n",
      "Loss : 1.4861031770706177\n",
      "Loss : 1.286325216293335\n",
      "Loss : 1.1658380031585693\n",
      "Loss : 1.0806772708892822\n",
      "Loss : 1.015419363975525\n",
      "Loss : 0.9630394577980042\n",
      "Loss : 0.9196972846984863\n",
      "Loss : 0.8830296993255615\n",
      "### 학습 종료 ###\n",
      "측정한 각각의 결과값 : 0.7785833477973938\n",
      "### 학습 시작 ###\n",
      "Loss : 11.858837127685547\n",
      "Loss : 1.7573554515838623\n",
      "Loss : 1.3606308698654175\n",
      "Loss : 1.1887990236282349\n",
      "Loss : 1.0856183767318726\n",
      "Loss : 1.0134406089782715\n",
      "Loss : 0.9584596753120422\n",
      "Loss : 0.914269745349884\n",
      "Loss : 0.8774898648262024\n",
      "Loss : 0.846147358417511\n",
      "### 학습 종료 ###\n",
      "측정한 각각의 결과값 : 0.7790833115577698\n",
      "최종 K-Fold 교차검증을 사용한 Accuracy : 0.7799999713897705\n"
     ]
    }
   ],
   "source": [
    "# Accuracy    \n",
    "predict = tf.argmax(H,1)\n",
    "correct = tf.equal(predict, tf.argmax(T,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "# K-Fold Cross Validation\n",
    "cv = 5          # Fold의 수\n",
    "results = []    \n",
    "                \n",
    "kf = KFold(n_splits=cv, shuffle=True) \n",
    "\n",
    "for training_idx, validation_idx in kf.split(norm_train_x):\n",
    "    training_x = norm_train_x[training_idx] # Fancy indexing\n",
    "    training_t = onehot_train_label[training_idx]\n",
    "    \n",
    "    val_x = norm_train_x[validation_idx]\n",
    "    val_t = onehot_train_label[validation_idx]\n",
    "    \n",
    "    run_train(sess,training_x,training_t)\n",
    "    acc = sess.run(accuracy, feed_dict={X:val_x, T:val_t})\n",
    "    print('측정한 각각의 결과값 : {}'.format(acc))\n",
    "    results.append(acc)\n",
    "\n",
    "\n",
    "print('최종 K-Fold 교차검증을 사용한 Accuracy : {}'.format(np.mean(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 값 : 1\n"
     ]
    }
   ],
   "source": [
    "# 공식을 이용해서 직접 img를 흑백처리\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = np.asarray(Image.open('C:/Users/s_csmscox/jupyterSave/8.png'))\n",
    "\n",
    "# 그레이 스케일링\n",
    "r = 0.2989\n",
    "g = 0.5870\n",
    "b = 0.1140\n",
    "gray = img[:, :, 0] * r + img[:, :, 1] * g + img[:, :, 2] * b\n",
    "img = Image.fromarray(gray)\n",
    "\n",
    "# 사이즈 조절\n",
    "img = img.resize((28,28))\n",
    "\n",
    "# 예측\n",
    "img = np.asarray(img)\n",
    "plt.imshow(img, cmap='gray') # cmap='gray_r의 경우 흑백 반전 = Greys'\n",
    "plt.show()\n",
    "\n",
    "img = 255 - img\n",
    "norm_img = scaler_test.transform(img.reshape(1,-1))\n",
    "\n",
    "result = sess.run(H, feed_dict={X: norm_img})\n",
    "\n",
    "for i in result:\n",
    "    m = i.max()\n",
    "    for j in range(10):\n",
    "        if i[j] == m:\n",
    "            print(\"예측 값 : {}\".format(j))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7832\n"
     ]
    }
   ],
   "source": [
    "result = sess.run(H, feed_dict={X: norm_test_x})\n",
    "pred = []\n",
    "\n",
    "for i in result:\n",
    "    m = i.max()\n",
    "    for j in range(10):\n",
    "        if i[j] == m:\n",
    "            pred.append(j)\n",
    "            break\n",
    "\n",
    "cnt = 0\n",
    "for predict, answer in zip(pred, test_label):\n",
    "    if predict == answer:\n",
    "        cnt += 1\n",
    "\n",
    "print((cnt/len(pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
