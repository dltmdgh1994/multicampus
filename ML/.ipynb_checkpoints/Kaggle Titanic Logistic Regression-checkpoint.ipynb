{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy import stats\n",
    "\n",
    "gs = pd.read_csv('./gender_submission.csv')\n",
    "train = pd.read_csv('./train.csv')\n",
    "test = pd.read_csv('./test.csv')\n",
    "\n",
    "train = train[['Survived', 'Pclass', 'SibSp', 'Parch', 'Sex', 'Age', 'Embarked']]\n",
    "test = test[['Pclass', 'SibSp', 'Parch', 'Sex', 'Age', 'Embarked']]\n",
    "\n",
    "# 남성 0, 여성 1\n",
    "train.loc[train['Sex']=='male', 'Sex'] = 0\n",
    "train.loc[train['Sex']=='female', 'Sex'] = 1\n",
    "\n",
    "test.loc[test['Sex']=='male', 'Sex'] = 0\n",
    "test.loc[test['Sex']=='female', 'Sex'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.58522796352584\n",
      "28.68708762886598\n"
     ]
    }
   ],
   "source": [
    "train_male_sum = train.loc[(train['Age'].isna() == False) & (train['Sex']==0) , 'Age'].sum()\n",
    "test_male_sum = test.loc[(test['Age'].isna() == False) & (test['Sex']==0) , 'Age'].sum()\n",
    "\n",
    "train_male_len = len(train.loc[(train['Age'].isna() == False) & (train['Sex']==0) , 'Age'])\n",
    "test_male_len = len(test.loc[(test['Age'].isna() == False) & (test['Sex']==0) , 'Age'])\n",
    "\n",
    "male_mean = (train_male_sum + test_male_sum) / (train_male_len + test_male_len)\n",
    "\n",
    "train_female_sum = train.loc[(train['Age'].isna() == False) & (train['Sex']==1) , 'Age'].sum()\n",
    "test_female_sum = test.loc[(test['Age'].isna() == False) & (test['Sex']==1) , 'Age'].sum()\n",
    "\n",
    "train_female_len = len(train.loc[(train['Age'].isna() == False) & (train['Sex']==1) , 'Age'])\n",
    "test_female_len = len(test.loc[(test['Age'].isna() == False) & (test['Sex']==1) , 'Age'])\n",
    "\n",
    "female_mean = (train_female_sum + test_female_sum) / (train_female_len + test_female_len)\n",
    "\n",
    "print(male_mean)\n",
    "print(female_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 남성 나이의 평균은 약 31세, 여성은 약 29세\n",
    "train.loc[(train['Age'].isna()) & (train['Sex']==0) , 'Age'] = 31\n",
    "train.loc[(train['Age'].isna()) & (train['Sex']==1) , 'Age'] = 29\n",
    "\n",
    "test.loc[(test['Age'].isna()) & (train['Sex']==0) , 'Age'] = 31\n",
    "test.loc[(test['Age'].isna()) & (train['Sex']==1) , 'Age'] = 29\n",
    "\n",
    "train['Age'] = train['Age'].round()\n",
    "test['Age'] = test['Age'].round()\n",
    "\n",
    "train.loc[train['Age'] < 8,'Age'] = 0\n",
    "train.loc[(train['Age'] >= 8) & (train['Age'] < 20),'Age'] = 1\n",
    "train.loc[(train['Age'] >= 20) & (train['Age'] < 65),'Age'] = 2\n",
    "train.loc[train['Age'] >= 65,'Age'] = 3\n",
    "\n",
    "train.loc[train['Age'] < 8,'Age'] = 0\n",
    "train.loc[(train['Age'] >= 8) & (train['Age'] < 20),'Age'] = 1\n",
    "train.loc[(train['Age'] >= 20) & (train['Age'] < 65),'Age'] = 2\n",
    "train.loc[train['Age'] >= 65,'Age'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train['Embarked']=='S', 'Embarked'] = 0\n",
    "train.loc[train['Embarked']=='C', 'Embarked'] = 1\n",
    "train.loc[train['Embarked']=='Q', 'Embarked'] = 2\n",
    "idx = train[train['Embarked'].isna()].index\n",
    "train = train.drop(idx)\n",
    "\n",
    "test.loc[test['Embarked']=='S', 'Embarked'] = 0\n",
    "test.loc[test['Embarked']=='C', 'Embarked'] = 1\n",
    "test.loc[test['Embarked']=='Q', 'Embarked'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = train[['Pclass', 'SibSp', 'Parch', 'Sex', 'Age', 'Embarked']].values\n",
    "t_data = train['Survived'].values.reshape(-1,1)\n",
    "\n",
    "scaler_x = MinMaxScaler() \n",
    "\n",
    "scaler_x.fit(x_data)\n",
    "\n",
    "scaled_x_data = scaler_x.transform(x_data)\n",
    "\n",
    "scaled_predict_data = scaler_x.transform(test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [[-0.92979159 -0.20819207 -0.01967036  2.60751042  0.          0.26020532]], b: [0.61374439]\n",
      "[0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 0 0 1 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 0 1\n",
      " 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 1 1 0 1 0\n",
      " 1 0 0 1 0 1 0 0 0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 1 1 0 1 1 0 1 0 0 1 0 0 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
      " 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 1 0 1 0 0 1 0 1 1 0 1 1 0 1 1 0\n",
      " 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
      " 0 1 1 1 1 1 0 1 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s_csmscox\\Anaconda3\\envs\\tf1\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "model = linear_model.LogisticRegression()\n",
    "\n",
    "model.fit(x_data,t_data)\n",
    "\n",
    "print('W: {}, b: {}'.format(model.coef_, model.intercept_))\n",
    "\n",
    "result = model.predict(test.values)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,6], dtype=tf.float32)\n",
    "T = tf.placeholder(shape=[None,1], dtype=tf.float32)\n",
    "\n",
    "# Weight & bias\n",
    "W = tf.Variable(tf.random.normal([6,1]), name='weight')\n",
    "b = tf.Variable(tf.random.normal([1]), name='bias')\n",
    "\n",
    "# Hypothesis\n",
    "logit = tf.matmul(X,W) + b\n",
    "H = tf.sigmoid(logit)\n",
    "\n",
    "# loss function(Cross Entropy)\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logit, \n",
    "                                                              labels=T))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-4).minimize(loss)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# parameter\n",
    "num_of_epoch = 1500\n",
    "batch_size = 100\n",
    "\n",
    "# 학습용 함수\n",
    "def run_train(sess,train_x, train_t):\n",
    "    print('### 학습 시작 ###')\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(num_of_epoch):\n",
    "        total_batch = int(train_x.shape[0] / batch_size)\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_x = train_x[i*batch_size:(i+1)*batch_size]\n",
    "            batch_t = train_t[i*batch_size:(i+1)*batch_size]           \n",
    "            _, loss_val = sess.run([train,loss],\n",
    "                                   feed_dict={X: batch_x,\n",
    "                                              T: batch_t})\n",
    "            \n",
    "        if step % 1000 == 0:\n",
    "            print('Loss : {}'.format(loss_val))\n",
    "    print('### 학습 종료 ###')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 학습 시작 ###\n",
      "Loss : 0.49943336844444275\n",
      "Loss : 0.4965958893299103\n",
      "### 학습 종료 ###\n",
      "### 학습 시작 ###\n",
      "Loss : 1.78566575050354\n",
      "Loss : 1.4777370691299438\n",
      "### 학습 종료 ###\n",
      "### 학습 시작 ###\n",
      "Loss : 1.8852237462997437\n",
      "Loss : 1.591780424118042\n",
      "### 학습 종료 ###\n",
      "### 학습 시작 ###\n",
      "Loss : 0.5741792321205139\n",
      "Loss : 0.5360026359558105\n",
      "### 학습 종료 ###\n",
      "### 학습 시작 ###\n",
      "Loss : 0.720916748046875\n",
      "Loss : 0.6987544298171997\n",
      "### 학습 종료 ###\n",
      "측정한 각각의 결과값 : [0.73595506, 0.3258427, 0.33707866, 0.7303371, 0.55932206]\n",
      "최종 K-Fold 교차검증을 사용한 Accuracy : 0.5377071499824524\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Accuracy 측정(정확도)    \n",
    "predict = tf.cast(H >= 0.5, dtype=tf.float32)\n",
    "correct = tf.equal(predict, T)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "# K-Fold Cross Validation\n",
    "cv = 5          # Fold의 수\n",
    "results = []     \n",
    "\n",
    "kf = KFold(n_splits=cv, shuffle=True) \n",
    "\n",
    "for training_idx, validation_idx in kf.split(scaled_x_data):\n",
    "    training_x = scaled_x_data[training_idx] # Fancy indexing\n",
    "    training_t = t_data[training_idx]\n",
    "    \n",
    "    val_x = scaled_x_data[validation_idx]\n",
    "    val_t = t_data[validation_idx]\n",
    "    \n",
    "    run_train(sess,training_x,training_t)\n",
    "    results.append(sess.run(accuracy, feed_dict={X:val_x, T:val_t}))\n",
    "\n",
    "print('측정한 각각의 결과값 : {}'.format(results))\n",
    "print('최종 K-Fold 교차검증을 사용한 Accuracy : {}'.format(np.mean(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = sess.run(predict, feed_dict={X: scaled_predict_data})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(6,)))\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dense(1,activation='relu'))\n",
    "model.compile(optimizer=SGD(learning_rate=1e-5), loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(scaled_x_data, t_data, epochs=700, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'], color='r')\n",
    "plt.plot(history.history['loss'], color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_val = model.predict(scaled_predict_data)\n",
    "result = tf.cast(predict_val >= 0.5, dtype=tf.int8).numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('./gender_submission.csv')\n",
    "sub['Survived'] = result\n",
    "\n",
    "sub.to_csv('gender_submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
